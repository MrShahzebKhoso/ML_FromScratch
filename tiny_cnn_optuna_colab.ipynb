{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f64e5e0",
   "metadata": {},
   "source": [
    "# Tiny CNN from Scratch — Math, NumPy, PyTorch, Feature Maps & Optuna Tuning\n",
    "\n",
    "**Colab-ready notebook**: Build a tiny convolutional neural network from first principles, visualize kernels & feature maps, and tune its hyperparameters with Optuna. This notebook is structured for teaching and reproducibility.\n",
    "\n",
    "**Sections:**\n",
    "1. Setup (install libraries)\n",
    "2. Math & numeric example\n",
    "3. Tiny CNN in NumPy (forward pass only)\n",
    "4. PyTorch TinyCNN implementation\n",
    "5. Visualizing kernels & feature maps\n",
    "6. Optuna hyperparameter tuning (objective + example)\n",
    "7. Experiments & plots\n",
    "\n",
    "Run on Google Colab (GPU recommended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c270a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (run in Colab)\n",
    "!pip install --quiet torch torchvision optuna matplotlib tqdm\n",
    "\n",
    "# Note: On Colab, use the GPU runtime for faster training (Runtime → Change runtime type → GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import optuna\n",
    "print('torch:', torch.__version__, 'optuna:', optuna.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41539bb9",
   "metadata": {},
   "source": [
    "## 2. Math & numeric example\n",
    "\n",
    "Small worked example: apply a 3×3 kernel to a 5×5 input (stride=1, no padding) and compute the output shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4138e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric example: 5x5 input convolved with 3x3 kernel\n",
    "x = np.arange(25).reshape(5,5)\n",
    "k = np.array([[1,0,-1],[1,0,-1],[1,0,-1]])\n",
    "\n",
    "def conv2d_simple(x, kernel, stride=1, padding=0):\n",
    "    if padding>0:\n",
    "        x = np.pad(x, pad_width=padding, mode='constant')\n",
    "    k = kernel.shape[0]\n",
    "    out_h = (x.shape[0] - k)//stride + 1\n",
    "    out_w = (x.shape[1] - k)//stride + 1\n",
    "    out = np.zeros((out_h, out_w), dtype=float)\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            patch = x[i*stride:i*stride+k, j*stride:j*stride+k]\n",
    "            out[i,j] = np.sum(patch * kernel)\n",
    "    return out\n",
    "\n",
    "print('input:\\n', x)\n",
    "print('\\nkernel:\\n', k)\n",
    "print('\\noutput:\\n', conv2d_simple(x,k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f803f4",
   "metadata": {},
   "source": [
    "## 3. Tiny CNN from scratch (NumPy) — forward pass only\n",
    "\n",
    "This section implements a minimal forward pass showing what convolution does under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "class TinyCNNNumPy:\n",
    "    def __init__(self):\n",
    "        # single-channel for simplicity\n",
    "        self.conv1 = np.random.randn(4, 1, 3, 3) * 0.1  # out_ch, in_ch, k, k\n",
    "        self.conv2 = np.random.randn(8, 4, 3, 3) * 0.1\n",
    "\n",
    "    def conv_layer(self, x, kernels, stride=1, padding=0):\n",
    "        # x shape: (C, H, W)\n",
    "        C_in, H, W = x.shape\n",
    "        C_out = kernels.shape[0]\n",
    "        k = kernels.shape[2]\n",
    "        if padding>0:\n",
    "            x = np.pad(x, ((0,0),(padding,padding),(padding,padding)), mode='constant')\n",
    "            H = x.shape[1]; W = x.shape[2]\n",
    "        out_h = (H - k)//stride + 1\n",
    "        out_w = (W - k)//stride + 1\n",
    "        out = np.zeros((C_out, out_h, out_w))\n",
    "        for o in range(C_out):\n",
    "            for i in range(out_h):\n",
    "                for j in range(out_w):\n",
    "                    s = 0.0\n",
    "                    for c in range(C_in):\n",
    "                        patch = x[c, i*stride:i*stride+k, j*stride:j*stride+k]\n",
    "                        s += np.sum(patch * kernels[o, c])\n",
    "                    out[o, i, j] = s\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (C, H, W)\n",
    "        x = self.conv_layer(x, self.conv1, padding=1)\n",
    "        x = relu(x)\n",
    "        x = x[:, ::2, ::2]  # simple 2x2 downsample (maxpool replacement for brevity)\n",
    "        x = self.conv_layer(x, self.conv2, padding=1)\n",
    "        x = relu(x)\n",
    "        x = x[:, ::2, ::2]\n",
    "        return x\n",
    "\n",
    "# demo with random input\n",
    "m = TinyCNNNumPy()\n",
    "inp = np.random.randn(1, 28, 28)\n",
    "out = m.forward(inp)\n",
    "print('output shape (numpy tinycnn):', out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87307022",
   "metadata": {},
   "source": [
    "## 4. PyTorch TinyCNN implementation\n",
    "\n",
    "Standard PyTorch model with two conv layers, pool, and a final linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26968542",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyCNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, n_classes=10, n_filters1=16, n_filters2=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, n_filters1, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_filters1, n_filters2, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(n_filters2 * 7 * 7, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# quick instantiation\n",
    "_model = TinyCNN()\n",
    "print(_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c342f99f",
   "metadata": {},
   "source": [
    "### Data: MNIST (small) — transforms and loaders\n",
    "\n",
    "Use MNIST for quick experiments. If you prefer CIFAR-10, change the dataset and model input channels accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3e4fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_ds = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "val_ds = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "print('train samples:', len(train_ds), 'val samples:', len(val_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec63436",
   "metadata": {},
   "source": [
    "### Training & evaluation helpers\n",
    "\n",
    "Functions to train one epoch, evaluate, and a small utility to set seeds for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ea34d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "def train_one_epoch(model, device, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    n = 0\n",
    "    for x,y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = out.argmax(dim=1)\n",
    "        correct += (preds==y).sum().item()\n",
    "        n += x.size(0)\n",
    "    return total_loss/n, correct/n\n",
    "\n",
    "\n",
    "def evaluate(model, device, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            preds = out.argmax(dim=1)\n",
    "            correct += (preds==y).sum().item()\n",
    "            n += x.size(0)\n",
    "    return total_loss/n, correct/n\n",
    "\n",
    "print('helpers ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113013e3",
   "metadata": {},
   "source": [
    "## 5. Visualizing kernels & feature maps\n",
    "\n",
    "Functions to plot filters and feature maps using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc31208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_kernels(conv_layer, figsize=(8,8), cmap='viridis'):\n",
    "    w = conv_layer.weight.data.clone().cpu()\n",
    "    # Normalize per-kernel\n",
    "    w_min, w_max = w.min(), w.max()\n",
    "    w = (w - w_min) / (w_max - w_min + 1e-9)\n",
    "    out_ch, in_ch, k, _ = w.shape\n",
    "    cols = in_ch\n",
    "    rows = out_ch\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*2, rows*2))\n",
    "    if rows==1 and cols==1:\n",
    "        axes = np.array([[axes]])\n",
    "    elif rows==1:\n",
    "        axes = np.array([axes])\n",
    "    elif cols==1:\n",
    "        axes = axes.reshape(rows,1)\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            axes[i,j].imshow(w[i,j], cmap=cmap)\n",
    "            axes[i,j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_feature_map(model, x, layer_name):\n",
    "    outputs = {}\n",
    "    def hook(module, inp, out):\n",
    "        outputs['fm'] = out.detach().cpu()\n",
    "    handle = getattr(model, layer_name).register_forward_hook(hook)\n",
    "    _ = model(x)\n",
    "    handle.remove()\n",
    "    return outputs.get('fm')\n",
    "\n",
    "\n",
    "def show_feature_maps(fm, max_channels=8, cmap='magma'):\n",
    "    # fm shape: (B, C, H, W)\n",
    "    fm = fm.squeeze(0)\n",
    "    C = fm.shape[0]\n",
    "    to_show = min(C, max_channels)\n",
    "    cols = 4\n",
    "    rows = (to_show + cols - 1)//cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*2, rows*2))\n",
    "    axes = np.array(axes)\n",
    "    for i in range(rows*cols):\n",
    "        r, c = divmod(i, cols)\n",
    "        if i < to_show:\n",
    "            axes[r,c].imshow(fm[i], cmap=cmap)\n",
    "            axes[r,c].axis('off')\n",
    "        else:\n",
    "            axes[r,c].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print('visualization helpers ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb961bc5",
   "metadata": {},
   "source": [
    "### Demo: visualize initial kernels and feature maps (random init)\n",
    "\n",
    "Run this cell to see initial random kernels and feature maps for a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f9874",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = TinyCNN().to(device)\n",
    "# show kernels for conv1\n",
    "show_kernels(model.conv1)\n",
    "\n",
    "# pick a sample image\n",
    "sample, _ = val_ds[0]\n",
    "x = sample.unsqueeze(0).to(device)\n",
    "fm1 = get_feature_map(model, x, 'conv1')\n",
    "show_feature_maps(fm1, max_channels=8)\n",
    "\n",
    "fm2 = get_feature_map(model, x, 'conv2')\n",
    "show_feature_maps(fm2, max_channels=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02bcede",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter tuning with Optuna\n",
    "\n",
    "Define an Optuna objective that trains for a few epochs and reports validation loss for pruning. Adjust search space as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d37520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_objective(trial):\n",
    "    # hyperparameters\n",
    "    lr = trial.suggest_loguniform('lr', 1e-4, 1e-1)\n",
    "    batch = trial.suggest_categorical('batch', [64, 128])\n",
    "    filters1 = trial.suggest_categorical('filters1', [8, 16, 32])\n",
    "    filters2 = trial.suggest_categorical('filters2', [16, 32, 64])\n",
    "\n",
    "    # data loaders with chosen batch\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_ds, batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = TinyCNN(in_channels=1, n_classes=10, n_filters1=filters1, n_filters2=filters2).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    epochs = 6\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, device, train_loader, optimizer, criterion)\n",
    "        val_loss, val_acc = evaluate(model, device, val_loader, criterion)\n",
    "        trial.report(val_loss, epoch)\n",
    "        # pruning\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    return val_loss\n",
    "\n",
    "# Example: create a study (don't run automatically to avoid long runs)\n",
    "# study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler())\n",
    "# study.optimize(optuna_objective, n_trials=20)  # adjust n_trials for your budget\n",
    "\n",
    "print('Optuna objective ready. To run tuning, uncomment the study code and choose n_trials.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16954389",
   "metadata": {},
   "source": [
    "## 7. Experiments & plots\n",
    "\n",
    "Suggested experiments:\n",
    "- Run a baseline with fixed hyperparameters for 6 epochs and record val accuracy\n",
    "- Run Optuna for 20–50 trials (or more if you have budget)\n",
    "- Compare baseline vs tuned best trial\n",
    "\n",
    "You can visualize Optuna results using `optuna.visualization` in a Colab environment."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
